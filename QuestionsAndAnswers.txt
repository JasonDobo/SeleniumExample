Questions1. What did you think of the provided acceptance criteria?As the main positive acceptance criteria for a story they are fine. I personally would have written then in the Gherkin syntax to ensure all acceptance criteria are defined in the same way. For example, I would write the first acceptance criteria as:- Given the homepage is displayed- When the user searches using a valid search criteria- Then a set of products are displayed to the userIn addition to the example criteria, I would also want to define some negative acceptance criteria and edge cases. 2. If this were a real story from a real life Product Owner - what questions would you ask?I would ask the following questions:-. Is the search button enabled if no text has been entered and what feedback is given to the user if the button is pressed-. Is there a limit to the number of characters the user can enter-. If spaces are used, do the results have to contain all words entered or only a partial match-. Is the search based of the descriptions of the products or using something more complex like facets-. Does the search bar except special characters i.e. @-. Does the search bar support copy and paste-. Is search bar supposed to sanitize the text, for example if the user puts in Javascript or regular expressions.3. Why did you choose to structure your code in the way you did?As this was the first ever web test I’ve written, I decide to contain all the code in a single class. As part of the class I created helper methods to handle finding of element and interaction methods for typical user actions. I also grouped user actions if they naturally fit together. 4. If you had more time what improvements would you make to your code?If I had more time, I would prefer to develop the automation using the page object model to reduce the amount of code duplication and enable code reuse between tests. I would also want to use Cucumber for this project. But I didn’t get time to try that.5. What is your usual approach to testing on a project? (Hint: talk about different levels of testing you would do; who would collaborate with whom etc)In my ideal project, the approach I would prefer to take is for testing at the 3 main levels of the test pyramid (Unit, Integration and End to End) with exploratory testing to help identify edge cases.Ideally we want to have as many unit tests as if feasible, as they are fast to run and easier to maintain. The easiest way to do this is to have the project developed using TDD as to ensure the behavior of the code being tested as code is developed. I would also pair a developer with a tester to look at the UI requirements, for example testing a text fields data validation can be done at any level, but is easiest at unit level and in doing so removes the need to test it at the UI level. For the benefits to be felt, the tester should understand what the units tests cover.UI integration testing with a native app is probably the hardest level to fill. (I realize that this is different in web sites as apposed to native apps). The best solution is to build the app with automation in mind from the start and have it support the loading of screens or activities with stub data defined by the tester. This will allow faster testing of isolated functionality, like a password reset.  These types of tests are in my experience the hardest to do and work best when the tester and developer pair on the test cases and the app supports this type of startup.The highest level is end to end testing, ideally you want to identify the most popular routes through your services and create end-to-end tests. You should also ensure that no single test becomes to complex or attempts to cover to much functionality. In the end you want a minimal number of end-to-end tests, which enable quick feedback to the developers, while cover the most important business cases. A product owner input is most important at this level. I would also use exploratory testing combined with test charters, for a final level of confidence. Test charters remove the need for detailed test specifications and in theory allows any team member to do exploratory testing. Though the tester will always have a better level of experience with this type. A further potential benefit of exploratory testing in that it can be started before a Story is finished, so long as the tester talks to the developer to understand what work is completed.At the start of every story I would ensure that as part of say a “definition of ready” each story is reviewed by a developer, tester and product owner/manager to ensure that the value is understood, it has clearly defined (positive and negative) behavior, is testable and is understood. This way even before the first line of code is written we are asking questions to understand what we trying to achieve. Quality is always more achievable when it is the responsibility of the whole team. 